{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Potential Fields (Magnetics) over TKC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "In this tutorial, we demonstrate how to invert magnetic field data in 3D using SimPEG.PF. It simulates a geophysical experiment over a synthetic\n",
    "kimberlite pipe model. The chosen geological model intends to replicate the Tli Kwi Cho kimberlite deposit, NWT. Using SimPEG Directives, we implement a sparse regularization function and recover both a smooth and a compact susceptibility model, which can used to infer geological information at depth. The same example was presented as a [poster](https://drive.google.com/open?id=0B-8Bv7qmQs23NHRTcXZ5WXVLdkE) at Scipy 2016.\n",
    "\n",
    "![Scipy_2016_PF_Thumbnail](../../../images/Scipy_2016_PF_Thumbnail.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We begin this story with some physics background. We need to establish the\n",
    "connection between rocks magnetic properties and the associated geophysical\n",
    "experiment. Maxwell's equations for a static electric field and in the absence\n",
    "of free-currents can be written as:\n",
    "\n",
    "$$\n",
    "\\nabla \\cdot \\mathbf{B} = 0 ,\\;\\ \\nabla \\times \\mathbf{H} = 0\n",
    "$$\n",
    "\n",
    "where $\\mathbf{B}$ and $\\mathbf{H}$ correspond to the magnetic\n",
    "flux density and magnetic field respectively. Both quantities are related by:\n",
    "\n",
    "$$\n",
    "\\mathbf{B} = \\mu \\mathbf{H} \\\\ \\mu = \\mu_0 ( 1 + \\kappa )\n",
    "$$\n",
    "\n",
    "where $\\mu$ is the magnetic permeability. In free-space, both\n",
    "$\\mathbf{B}$ and $\\mathbf{H}$ are linearly related by the magnetic\n",
    "permealitity of free-space $\\mu_0$. In matter however, the magnetic flux\n",
    "can be increased proportionally on how easily magnetic material gets\n",
    "polarized, quantified by the magnetic susceptibility $\\kappa$. In a\n",
    "macroscopic point of view, the magnetic property of matter are generally\n",
    "described in terms of magnetization per unit volume such that:\n",
    "\n",
    "$$\n",
    "\\mathbf{M} = \\kappa \\mathbf{H_s + H_0} + \\mathbf{M_r}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{M}$ can be oriented in any specific direction due to\n",
    "secondary local fields ($\\mathbf{H_s}$) and/or due to permanent dipole\n",
    "moments ($\\mathbf{M_r}$). For simplicity we will here assume a purely\n",
    "induced response due to the Earth's $\\mathbf{H_0}$. Using a few vector\n",
    "identities, we can re-write the magnetic field due to magnetized material in\n",
    "terms of a scalar potential:\n",
    "\n",
    "$$\n",
    "\\phi = \\frac{1}{4\\pi}  \\int_{V}    \\nabla \\left(\\frac{1}{r}\\right) \\cdot \\mathbf{H}_0 \\kappa  \\; dV\n",
    "$$\n",
    "\n",
    "where $r$ defines the relative position between an observer and the\n",
    "magnetic source. Taking the divergence of this potential yields:\n",
    "\n",
    "$$\n",
    "\\mathbf{b} = \\frac{\\mu_0}{4\\pi}  \\int_{V}  \\nabla \\nabla \\left(\\frac{1}{r}\\right) \\cdot \\mathbf{H}_0 \\kappa \\; dV\n",
    "$$\n",
    "\n",
    "Great, we have a general expression relating any secondary magnetic flux due to\n",
    "magnetic material"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Problem\n",
    "\n",
    "Assuming a purely induced response, we can solve the integral analytically. As\n",
    "derived by Sharma (1966), the integral can be evaluated for rectangular prisms\n",
    "such that:\n",
    "\n",
    "$$\n",
    "\\mathbf{b} =  \\mathbf{T} \\cdot \\mathbf{H}_0 \\; \\kappa\n",
    "$$\n",
    "\n",
    "Where the tensor matrix $\\bf{T}$ relates the vector magnetization\n",
    "$\\mathbf{M}$ inside a single cell to the components of the field\n",
    "$\\mathbf{b}$ observed at a given location:\n",
    "\n",
    "$$\n",
    "\\mathbf{T} = \\begin{pmatrix} T_{xx} & T_{xy} & T_{xz}    \\\\ T_{yx} &\n",
    "T_{yy} & T_{yz}    \\\\ T_{zx} & T_{zy} & T_{zz} \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "In general, we discretize the earth into a collection of cells, each\n",
    "contributing to the magnetic data such that giving rise to a large and dense\n",
    "linear system of the form:\n",
    "\n",
    "$$\n",
    "\\mathbf{b} = \\sum_{j=1}^{nc} \\mathbf{T}_j \\cdot \\mathbf{H}_0 \\; \\kappa_j\n",
    "$$\n",
    "\n",
    "In most geophysical surveys, we are not collecting all three components, but\n",
    "rather the magnitude of the field, or *Total Magnetic Intensity* (TMI) data.\n",
    "Because the inducing field is really large, we will assume that the anomalous\n",
    "fields are parallel to $H_0$:\n",
    "\n",
    "$$\n",
    "d^{TMI}  = \\mathbf{\\hat H}_0 \\cdot \\mathbf{b}\n",
    "$$\n",
    "\n",
    "We then end up with a much smaller system:\n",
    "\n",
    "$$\n",
    "d^{TMI} = \\mathbf{F}\\; \\boldsymbol{\\kappa}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{F} \\in \\mathbb{R}^{nd \\times nc}$ is our *forward*\n",
    "operator and $\\kappa$ is the physical property describing the Earth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started\n",
    "\n",
    "In order to define a geophysical experiment we need set several important\n",
    "parameters, such as a mesh, data location, inversion parameters and so on.\n",
    "While we could set all of those parameters manually, SimPEG.PF gives the\n",
    "option to work with an input file, capturing all the necessary information to\n",
    "run the inversion. In preparation for this synthetic example, we put together\n",
    "all necessary files and added them to a working directory. The input file can\n",
    "then be loaded and easily accessed through the Driver class:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Start by importing SimPEG, the potential fields package and \n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from SimPEG import Mesh\n",
    "from SimPEG import Utils\n",
    "from SimPEG import Maps\n",
    "from SimPEG import Regularization\n",
    "from SimPEG import DataMisfit\n",
    "from SimPEG import Optimization\n",
    "from SimPEG import InvProblem\n",
    "from SimPEG import Directives\n",
    "from SimPEG import Inversion\n",
    "from SimPEG import PF\n",
    "import SimPEG.PF as PF\n",
    "from SimPEG.Utils.io_utils import download\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download files from the remote repository\n",
    "\n",
    "# This is where the files are stored on the cloud\n",
    "url = 'https://storage.googleapis.com/simpeg/tkc_synthetic/potential_fields/'\n",
    "cloudfiles = ['MagData.obs', 'Mesh.msh', 'Initm.sus', 'SimPEG_PF_Input.inp']\n",
    "\n",
    "psep = os.path.sep\n",
    "basePath = os.path.expanduser('~/Downloads/simpegtemp')\n",
    "download([url+f for f in cloudfiles], folder=basePath, overwrite=True)\n",
    "\n",
    "input_file = basePath + psep + cloudfiles[3]\n",
    "driver = PF.MagneticsDriver.MagneticsDriver_Inv(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Objects loaded from the input file are then accessible like this\n",
    "mesh = driver.mesh\n",
    "initm = driver.m0.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input file looks like this:\n",
    "\n",
    "```\n",
    "====    ==============   ===================================================================================\n",
    "Line    Input            Description\n",
    "====    ==============   ===================================================================================\n",
    "1       Mesh.msh         Mesh file*\n",
    "2       Data.obs         Data file*\n",
    "3       VALUE -100       Topography file* | null (all included)\n",
    "4       FILE Initm.mod   Starting model* | VALUE ##\n",
    "5       VALUE 0          Reference model* | VALUE ##\n",
    "6       DEFAULT          Magnetization file* | DEFAULT\n",
    "7       DEFAULT          Cell weight file* | DEFAULT\n",
    "8       DEFAULT          Target Chi factor VALUE | DEFAULT (1)\n",
    "9       DEFAULT          Scaling parameters for regularization (alpha_s, alpha_x, alpha_y, alpha_z)\n",
    "10      VALUE 0 1        Lower and upper bound values\n",
    "11      VALUE 0 1 1 1    Lp-norms applied on model and model gradients (p,q_x,q_y,q_z)\n",
    "12      DEFAULT          Treshold parameter for the norms (\\epsilon_p,\\epsilon_q) | DEFAULT\n",
    "Note                     * UBC file format\n",
    "====    ==============   ===================================================================================\n",
    "```\n",
    "\n",
    "We will use each elements later, but for now, this how the inversion\n",
    "is initiated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and Mapping\n",
    "\n",
    "Since we have already loaded the model in a rectangular mesh, we can plot it\n",
    "with SimPEG's built-in functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "initm[initm==-100] = np.nan\n",
    "\n",
    "# Create a figure and plot sections\n",
    "fig, ax1 = plt.figure(), plt.subplot(1,2,1)\n",
    "mesh.plotSlice(initm, ax = ax1, normal='Z', ind=18, clim = (0,0.02), pcolorOpts={'cmap':'viridis'})\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.title('Z: '+str(mesh.vectorCCz[18]) + \" m\")\n",
    "\n",
    "ax2 = plt.subplot(1,2,2)\n",
    "mesh.plotSlice(initm, ax = ax2, normal='Y', ind=16, clim = (0,0.02), pcolorOpts={'cmap':'viridis'})\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.title('Y: '+str(mesh.vectorCCy[16])+' m')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that some of the cells in the model are air and show as white. The code\n",
    "will detected the air cells from the VALUE specified on line 3 of the input\n",
    "file. These cells are ignored by the code. Alternatively, the user can input a\n",
    "topography file or an active model specifying the status of each cells\n",
    "(0:inactive, 1:active-dynamic, -1:active-static)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "Great, now that we have a mesh and a model, we only need to specify a survey\n",
    "(i.e. where is the data). Once again, an observation file is provided, as\n",
    "specified on Line 2 of the input file. We can now forward model some magnetic\n",
    "data above the synthetic kimberlite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the survey\n",
    "survey = driver.survey\n",
    "\n",
    "# Get the active cells (below topography)\n",
    "actv = driver.activeCells\n",
    "\n",
    "# Create mapping to come back from the reduce space later\n",
    "idenMap = Maps.IdentityMap(nP=len(actv))\n",
    "\n",
    "# Now that we have a model and a survey we can build the linear system ...\n",
    "# (use the argument forwardOnly=True to avoid storing the dense forward matrix)\n",
    "prob = PF.Magnetics.MagneticIntegral(mesh, chiMap=idenMap, actInd=actv, rtype = 'tmi')\n",
    "\n",
    "# Pair the survey and problem (data and model space)\n",
    "survey.pair(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Forward operators and data are calculated here (wait for it!)\n",
    "d = prob.fields(driver.m0)\n",
    "\n",
    "# Add noise to the data and assign uncertainties\n",
    "survey.dobs = d + np.random.randn(len(d)) # We add some random Gaussian noise (1 nT)\n",
    "survey.std = np.ones(len(d))*1. # Assign flat uncertainties (1 nT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Then we can plot with the build-in function\n",
    "PF.Magnetics.plot_obs_2D(survey.srcField.rxList[0].locs,d=survey.dobs ,varstr='Mag Obs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse Problem\n",
    "\n",
    "\n",
    "We have generated synthetic data, we now what to see if we can solve the\n",
    "inverse problem. Using the usual formulation, we seek a model that can\n",
    "reproduce the data, let’s say a least-squares measure of the form:\n",
    "\n",
    "$$\n",
    "\\phi_d =\\|\\mathbf{W}_d \\left( \\mathbf{F}\\;\\mathbf{m} - \\mathbf{d}^{obs} \\right)\\|_2^2\\;,\n",
    "$$\n",
    "\n",
    "where $\\mathbf{W}_d$ are estimated data uncertainties\n",
    "The inverse problem is hard because we don’t have great data coverage, and the\n",
    "Earth is big, and there is usually noise in the data. So we need to add\n",
    "something to regularize it. The simplest way to do it is to penalize solutions\n",
    "that won’t make sense geologically, for example to assume that the model is\n",
    "*small* and *smooth*. Most inversion codes use the l2-norm measure such that:\n",
    "\n",
    "$$\n",
    "\\phi_m = {\\| \\mathbf{W}_s \\;( \\mathbf{m - m^{ref}})\\|}^2_2  + \\sum_{i = x,y,z}  {\\|   \\mathbf{W}_i  \\; \\mathbf{G}_i \\; \\mathbf{m}\\|}^2_2\n",
    "$$\n",
    "\n",
    "where $m^{ref}$ is any a priori knowledge that we might have about the\n",
    "solution and $\\mathbf{G}_x, \\mathbf{G}_y, \\mathbf{G}_z$ are finite\n",
    "difference operators measuring the model spatial gradients along orthogonal\n",
    "directions. In a purely *unconstrained* case, $m^{ref}$ is usually equal\n",
    "to some background value (i.e. zero susceptibility).\n",
    "The full objective function to be minimized can be written as:\n",
    "\n",
    "$$\n",
    "\\phi (m) =  \\phi_d + \\beta \\phi_m\n",
    "$$\n",
    "\n",
    "which will yield our usual function that minimize the data error and model\n",
    "structure. The trade-off parameter $\\beta$ is adjusted in order to get a\n",
    "*good* balance between data misfit and model\n",
    "\n",
    "We propose a fancier regularization function that can allow to recover *sparse* and *blocky* solutions.\n",
    "Starting with the well known Ekblom norm:\n",
    "\n",
    "$$\n",
    "\\phi_m =  \\sum_{i=1}^{nc} {(x_i^2 + \\epsilon^2)}^{p/2}\n",
    "$$\n",
    "\n",
    "where $x_i$ denotes some function of the model parameter, and $\\epsilon$ is a small value to avoid singularity as $m\\rightarrow0$.\n",
    "\n",
    "For p=2, we get the usual least-squares measure and we recover the\n",
    "regularization presented above. For $p \\leq 1$, the function becomes\n",
    "non-linear which requires some tweaking. We can linearize the function by\n",
    "updating the penality function iteratively, commonly known as an Iterative Re-\n",
    "weighted Least-Squares (IRLS) method. The regularization function becomes:\n",
    "\n",
    "$$\n",
    "\\phi_m^{(k)} =  \\frac{1}{2}\\sum_{i=1}^{nc} r_i \\; x_i^2\n",
    "$$\n",
    "\n",
    "where we added the superscript $\\square^{(k)}$ to denote the IRLS iterations.\n",
    "The weights $r(x)$ are computed from model values obtained at a previous\n",
    "iteration such that:\n",
    "\n",
    "$$\n",
    "{r}_i  ={\\Big( {({x_i}^{(k-1)})}^{2} + \\epsilon^2\n",
    "\\Big)}^{p/2 - 1}\n",
    "$$\n",
    "\n",
    "where ${r}(x) \\in \\mathbb{R}^{nc}$.\n",
    "\n",
    "In matrix form, our objective function simply becomes:\n",
    "\n",
    "$$\n",
    "\\phi(m) =   \\|\\mathbf{W}_d \\left( \\mathbf{F}\\;\\mathbf{m} - \\mathbf{d}^{obs} \\right)\\|_2^2 + \\beta \\Big [ {\\| \\mathbf{W}_s \\;\\mathbf{R}_s\\;( \\mathbf{m - m^{ref}})\\|}^2_2  + \\sum_{i = x,y,z}  {\\|   \\mathbf{W}_i\\; \\mathbf{R}_i  \\; \\mathbf{G}_i \\; \\mathbf{m}\\|}^2_2  \\Big ]\n",
    "$$\n",
    "\n",
    "where the IRLS weights $\\mathbf{R}_s$ and $\\mathbf{R}_i$ are diagonal matrices defined as:\n",
    "\n",
    "$$\n",
    "{R}_{s_{jj}}  =  \\sqrt{\\eta_p}{\\Big[ {({m_j}^{(k-1)})}^{2} + \\epsilon_p^2 \\Big]}^{(p/2 - 1)/2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "{R}_{i_{jj}}  =  \\sqrt{\\eta_q}{\\Big[ {\\left ({{(G_i\\;m^{(k-1)})}_j }\\right)}^{2} + \\epsilon_q^2 \\Big]}^{(q/2 - 1)/2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\eta_p =  {\\epsilon_p}^{(1-p/2)}\\;,\n",
    "$$\n",
    "$$\n",
    "\\eta_q =   {\\epsilon_q}^{(1-q/2)}\n",
    "$$\n",
    "\n",
    "we added two scaling parameters $\\eta_p$ and $\\eta_q$ for reasons that we won't dicuss here, but turn out to be important to get stable solves.\n",
    "\n",
    "In order to initialize the IRLS and get an estimate for the stabilizing\n",
    "parameters $\\epsilon_p$ and $\\epsilon_q$, we first invert with the\n",
    "smooth $l_2$-norm. Once the target data misfit has been achieved, the\n",
    "inversion switches to the sparse regularization. This way we get a good\n",
    "starting point, hopefully close enough to the true solution. The whole IRLS\n",
    "process is implemented with a directive added to the inversion workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# It is potential fields, so we will need to push the inverison down\n",
    "# Create distance weights from our linera forward operator\n",
    "wr = np.sum(prob.G**2.,axis=0)**0.5\n",
    "wr = ( wr/np.max(wr) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# REGULARIZATION\n",
    "# Here is where the norms are applied\n",
    "# Use pick a treshold parameter empirically based on the distribution of model\n",
    "# parameters (run last cell to see the histogram before and after IRLS)\n",
    "reg = Regularization.Sparse(mesh, indActive=actv, mapping=idenMap)\n",
    "reg.cell_weights = wr\n",
    "reg.norms=driver.lpnorms\n",
    "reg.eps_p = 3e-4\n",
    "reg.eps_q = 3e-4\n",
    "\n",
    "# MISFIT FUNCTION\n",
    "dmis = DataMisfit.l2_DataMisfit(survey)\n",
    "dmis.W = 1/survey.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# OPTIMIZATION\n",
    "# We solve the inverse problem with a projected Gauss-Newton solver\n",
    "opt = Optimization.ProjectedGNCG(maxIter=100 ,lower=0.,upper=1., maxIterLS = 20, maxIterCG= 10, tolCG = 1e-3)\n",
    "\n",
    "# INVERSE PROBLEM\n",
    "# Put all the components together\n",
    "invProb = InvProblem.BaseInvProblem(dmis, reg, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DIRECTIVES\n",
    "# We add a few directives\n",
    "# First to guess the initial beta\n",
    "betaest = Directives.BetaEstimate_ByEig()\n",
    "\n",
    "# Second, we add a pre-conditioner to speedup the CG solves\n",
    "update_Jacobi = Directives.Update_lin_PreCond()\n",
    "\n",
    "# This is the directive that will orchestrate the IRLS steps\n",
    "IRLS = Directives.Update_IRLS(f_min_change = 1e-4, minGNiter=3)\n",
    "\n",
    "# We add the directives to the inverse problem\n",
    "inv = Inversion.BaseInversion(invProb, directiveList=[betaest,IRLS,update_Jacobi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SOLVING\n",
    "# Finally, we run inversion...\n",
    "m0 = np.ones(len(actv))*1e-4\n",
    "mrec = inv.run(m0)\n",
    "\n",
    "\n",
    "# Create active map to return to full space after the inversion \n",
    "actvMap = Maps.InjectActiveCells(mesh, actv, -100)\n",
    "\n",
    "# Map to full space the final model and l2 model\n",
    "m_lp = actvMap*mrec\n",
    "m_l2 = actvMap*IRLS.l2model\n",
    "\n",
    "\n",
    "# Once it is done, we can save the models (l2 and lp) to a file\n",
    "Mesh.TensorMesh.writeModelUBC(mesh, basePath + os.path.sep +  'SimPEG_MAG_l2l2.sus',m_l2)\n",
    "Mesh.TensorMesh.writeModelUBC(mesh, basePath + os.path.sep +  'SimPEG_MAG_lplq.sus',m_lp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot sections and compare the smooth and compact models with the\n",
    "true solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mesh = Mesh.TensorMesh.readUBC(basePath + os.path.sep + \"Mesh.msh\")\n",
    "\n",
    "# Load models\n",
    "m_lp = Mesh.TensorMesh.readModelUBC(mesh, basePath + os.path.sep +  \"SimPEG_MAG_lplq.sus\")\n",
    "m_l2 = Mesh.TensorMesh.readModelUBC(mesh, basePath + os.path.sep +  \"SimPEG_MAG_l2l2.sus\")\n",
    "m_true = Mesh.TensorMesh.readModelUBC(mesh, basePath + os.path.sep +  \"Initm.sus\")\n",
    "\n",
    "m_lp[m_lp==-100] = np.nan\n",
    "m_l2[m_l2==-100] = np.nan\n",
    "m_true[m_true==-100] = np.nan\n",
    "\n",
    "fig = plt.figure()\n",
    "vmin, vmax = 0.0, 0.015\n",
    "xmin, xmax = -500 + 557300, 500 + 557300\n",
    "ymin, ymax = -500 + 7133600, 500 + 7133600\n",
    "zmin, zmax = -500 + 450, 0 + 450\n",
    "indz = 17\n",
    "indx = 17\n",
    "\n",
    "# Axis label\n",
    "x = np.linspace(xmin+200, xmax-200,3)\n",
    "y = np.linspace(zmin+50, zmax-50,3)\n",
    "\n",
    "ax1 = plt.subplot(1,1,1)\n",
    "pos =  ax1.get_position()\n",
    "ax1.set_position([pos.x0-0.1, pos.y0+0.3,  pos.width*0.5, pos.height*0.5])\n",
    "dat = mesh.plotSlice(m_l2, ax = ax1, normal='Z', ind=indz, clim=np.r_[vmin, vmax],pcolorOpts={'cmap':'viridis'})\n",
    "#     plt.colorbar(dat[0])\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.title('Smooth')\n",
    "ax1.xaxis.set_visible(False)\n",
    "plt.xlim(xmin, xmax)\n",
    "plt.ylim(ymin, ymax)\n",
    "plt.ylabel('Northing (m)')\n",
    "labels = ax1.get_yticklabels()\n",
    "plt.setp(labels, rotation=90)\n",
    "\n",
    "# ax2 = plt.subplot(2,2,3)\n",
    "pos =  ax1.get_position()\n",
    "ax2 = fig.add_axes([pos.x0+0.0525, pos.y0 - 0.315,  pos.width*0.725, pos.height])\n",
    "# ax2.yaxis.set_visible(False)\n",
    "# ax2.set_position([pos.x0 -0.04 , pos.y0,  pos.width, pos.height])\n",
    "\n",
    "dat = mesh.plotSlice(m_l2, ax = ax2, normal='Y', ind=indx, clim=np.r_[vmin, vmax],pcolorOpts={'cmap':'viridis'})\n",
    "#     plt.colorbar(dat[0])\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.title('')\n",
    "plt.xlim(xmin, xmax)\n",
    "plt.ylim(zmin, zmax)\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(map(str, map(int, x)),size=12)\n",
    "plt.xlabel('Easting (m)')\n",
    "plt.ylabel('Elev. (m)')\n",
    "ax2.set_yticks(y)\n",
    "ax2.set_yticklabels(map(str, map(int, y)),size=12)\n",
    "labels = ax2.get_yticklabels()\n",
    "plt.setp(labels, rotation=90)\n",
    "\n",
    "## Add compact model\n",
    "ax3 = fig.add_axes([pos.x0+0.3, pos.y0,  pos.width, pos.height])\n",
    "dat = mesh.plotSlice(m_lp, ax = ax3, normal='Z', ind=indz, clim=np.r_[vmin, vmax],pcolorOpts={'cmap':'viridis'})\n",
    "#     plt.colorbar(dat[0])\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.title('Compact')\n",
    "ax3.xaxis.set_visible(False)\n",
    "ax3.yaxis.set_visible(False)\n",
    "plt.xlim(xmin, xmax)\n",
    "plt.ylim(ymin, ymax)\n",
    "\n",
    "ax4 = fig.add_axes([pos.x0+0.3525, pos.y0 - 0.315,  pos.width*0.725, pos.height])\n",
    "# ax2.yaxis.set_visible(False)\n",
    "# ax2.set_position([pos.x0 -0.04 , pos.y0,  pos.width, pos.height])\n",
    "\n",
    "dat = mesh.plotSlice(m_lp, ax = ax4, normal='Y', ind=indx, clim=np.r_[vmin, vmax],pcolorOpts={'cmap':'viridis'})\n",
    "#     plt.colorbar(dat[0])\n",
    "plt.gca().set_aspect('equal')\n",
    "ax4.yaxis.set_visible(False)\n",
    "plt.title('')\n",
    "plt.xlim(xmin, xmax)\n",
    "plt.ylim(zmin, zmax)\n",
    "ax4.set_xticks(x)\n",
    "ax4.set_xticklabels(map(str, map(int, x)),size=12)\n",
    "plt.xlabel('')\n",
    "# ylabel('Elev. (m)')\n",
    "\n",
    "## Add True model\n",
    "ax5 = fig.add_axes([pos.x0+0.6, pos.y0,  pos.width, pos.height])\n",
    "dat = mesh.plotSlice(m_true, ax = ax5, normal='Z', ind=indz, clim=np.r_[vmin, vmax],pcolorOpts={'cmap':'viridis'})\n",
    "#     plt.colorbar(dat[0])\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.title('True')\n",
    "ax5.xaxis.set_visible(False)\n",
    "ax5.yaxis.set_visible(False)\n",
    "plt.xlim(xmin, xmax)\n",
    "plt.ylim(ymin, ymax)\n",
    "\n",
    "ax6 = fig.add_axes([pos.x0+0.6525, pos.y0 - 0.315,  pos.width*0.725, pos.height])\n",
    "# ax2.yaxis.set_visible(False)\n",
    "# ax2.set_position([pos.x0 -0.04 , pos.y0,  pos.width, pos.height])\n",
    "\n",
    "dat = mesh.plotSlice(m_true, ax = ax6, normal='Y', ind=indx, clim=np.r_[vmin, vmax],pcolorOpts={'cmap':'viridis'})\n",
    "#     plt.colorbar(dat[0])\n",
    "plt.gca().set_aspect('equal')\n",
    "ax6.yaxis.set_visible(False)\n",
    "plt.title('')\n",
    "plt.xlim(xmin, xmax)\n",
    "plt.ylim(zmin, zmax)\n",
    "ax6.set_xticks(x)\n",
    "ax6.set_xticklabels(map(str, map(int, x)),size=12)\n",
    "plt.xlabel('')\n",
    "# ylabel('Elev. (m)')\n",
    "\n",
    "pos =  ax4.get_position()\n",
    "cbarax = fig.add_axes([pos.x0 , pos.y0+0.05 ,  pos.width, pos.height*0.1])  ## the parameters are the specified position you set\n",
    "cb = fig.colorbar(dat[0],cax=cbarax, orientation=\"horizontal\", ax = ax4, ticks=np.linspace(vmin,vmax, 4),format='%.3f')\n",
    "cbarax.tick_params(labelsize=12)\n",
    "# cb.ax.xaxis.set_label_position('top')\n",
    "cb.set_label(\"Susceptibility (SI)\",size=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove downloaded files\n",
    "import shutil\n",
    "shutil.rmtree(basePath)\n",
    "\n",
    "# [os.remove(basePath + psep +f) for f in cloudfiles]\n",
    "# os.removedirs(os.path.expanduser(basePath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "\n",
    "We have inverted magnetic field data over a synthetic kimberlite pipe, using\n",
    "both a smooth and compact penalty. The smooth model gives a conservative and robust estimate of\n",
    "the kimberlite pipe location, as well as providing an excellent starting point\n",
    "for the sparse regularization. The compact model on the other hand gives a\n",
    "much closer estimate of susceptibility values and shape of the magnetic\n",
    "anomaly. More details about the scaled IRLS method can be found in this [thesis](https://open.library.ubc.ca/cIRcle/collections/ubctheses/24/items/1.0166794)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
